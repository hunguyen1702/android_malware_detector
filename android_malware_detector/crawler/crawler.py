import abc
import urllib
import subprocess
from threading import Thread
from bs4 import BeautifulSoup


class APKCrawler(Thread):

    URL = ''
    RESOURCE = ''

    def __init__(self, configurations, ID="APKCrawler"):
        Thread.__init__(self)
        try:
            self.ID = ID
            self.PAGE_RANGE = configurations['RANGE']
            self.DIR = configurations['SAVING_DIR']
        except KeyError, e:
            print '[ERROR] Cannot init crawler. {}'.format(e)

    @abc.abstractmethod
    def _get_apk_link_from_page(self, page_link):
        return []

    @abc.abstractmethod
    def _get_apk_download_link(self, links):
        return []

    def _download_apk(self, link):
        print "[INFO][DOWNLOAD_APK] Getting apk from {}".format(link)
        subprocess.call("wget -P {} \"{}\"".format(self.DIR, link), shell=True)

    def _fetch_page(self, link):
        page = urllib.urlopen(link)
        page = page.read()
        page = BeautifulSoup(page, 'html.parser')
        return page

    def run(self):
        try:
            print "[INFO] STARTING CRAWLER..."
            start_page = self.PAGE_RANGE[0]
            end_page = self.PAGE_RANGE[1] + 1
            for page in range(start_page, end_page):
                apk_page = '{}{}'.format(self.URL, self.RESOURCE.format(page))
                print "[INFO][FETCH_LINK_PAGE] Getting apk links from page: {}".format(apk_page)
                apk_links = self._get_apk_link_from_page(apk_page)
                print "[INFO][FETCH_DOWNLOAD_LINK] Getting download links"
                apk_download_links = self._get_apk_download_link(apk_links)
                for link in apk_download_links:
                    self._download_apk(link)
        except Exception, e:
            print "[ERROR] Crawler running error. {}".format(e)


class APKCrawlerMOB(APKCrawler):
    URL = "http://apps.mob.org/"
    RESOURCE = "page-{}/"

    def __init__(self, configurations, ID="APKCrawler"):
        Thread.__init__(self)
        try:
            self.ID = ID
            # self.URL = "http://apps.mob.org/"
            # self.RESOURCE = "page-{}/"
            self.PAGE_RANGE = configurations['RANGE']
            self.DIR = configurations['SAVING_DIR']
        except KeyError, e:
            print '[ERROR] Cannot init crawler. {}'.format(e)

    def _get_apk_link_from_page(self, page_link):
        page = self._fetch_page(page_link)
        for child in page.find_all('a', {'class': 'btn btn-green'}):
            yield child.get('href')

    def _get_apk_download_link(self, links):
        for link in links:
            apk_page = self._fetch_page(link)
            for child in apk_page.find_all('div', {'class': 'qr-code-link'}):
                yield child.get('data-url')


class APKCrawlerAAF(APKCrawler):

    URL = "http://www.androidapksfree.com/"
    RESOURCE = "applications/apps/page/{}/"

    def __init__(self, configurations, ID="APKCrawler"):
        Thread.__init__(self)
        try:
            self.ID = ID
            # self.URL = "http://www.androidapksfree.com/"
            # self.RESOURCE = "applications/apps/page/{}/"
            self.PAGE_RANGE = configurations['RANGE']
            self.DIR = configurations['SAVING_DIR']
        except KeyError, e:
            print '[ERROR] Cannot init crawler. {}'.format(e)

    def _get_apk_link_from_page(self, page_link):
        page = self._fetch_page(page_link)
        for child in page.find_all('a', {'title': 'Read More'}):
            yield child.get('href')

    def _get_apk_download_link(self, links):
        for link in links:
            apk_page = self._fetch_page(link)
            for child in apk_page.find_all('a'):
                if child.string == 'Download APK from secure server >>':
                    yield child.get('href')
